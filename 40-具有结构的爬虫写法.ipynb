{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from fake_useragent import UserAgent\n",
    "from lxml import etree\n",
    "\n",
    "# 爬取糗事百科文字中的所有笑话\n",
    "'''\n",
    "每个方法都干自己的事情\n",
    "'''\n",
    "\n",
    "# url管理\n",
    "class URLManager(object):\n",
    "    def __init__(self):\n",
    "        # 初始化容器：空list\n",
    "        self.new_url = []\n",
    "        self.old_url = []\n",
    "\n",
    "    # 获取一个url\n",
    "    def get_new_url(self):\n",
    "        # 从新的列表中取出来放入老的列表\n",
    "        url = self.new_url.pop()\n",
    "        self.old_url.append(url)\n",
    "        return url\n",
    "\n",
    "    # 增加一个url\n",
    "    def add_new_url(self,url):\n",
    "        # 已经存在于列表中和爬取过的url不用添加，url 不是空的\n",
    "        if url not in self.new_url and url and url not in self.old_url:\n",
    "            self.new_url.append(url)\n",
    "\n",
    "    # 增加多个url\n",
    "    def add_new_urls(self,urls):\n",
    "        for url in urls:\n",
    "            self.add_new_url(url)\n",
    "\n",
    "    # 判断是否还有可以爬取的url\n",
    "    def has_new_url(self):\n",
    "        return self.get_new_url_size() > 0\n",
    "        # 获取可以爬取的数量\n",
    "\n",
    "    def get_new_url_size(self):\n",
    "        return len(self.new_url)\n",
    "\n",
    "    # 获取已经爬取的数量\n",
    "    def get_old_url_size(self):\n",
    "        return len(self.old_url)\n",
    "\n",
    "# 爬取\n",
    "class Downloader:\n",
    "    def download(self, url):\n",
    "        response = requests.get(url, headers={\"User-Agent\": UserAgent().random})\n",
    "        if response.status_code == 200:\n",
    "            response.encoding = 'utf-8'\n",
    "            return response.text\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "# 解析\n",
    "class Parser:\n",
    "    def parse(self, html):\n",
    "        e = etree.HTML(html)\n",
    "        datas = self.parse_info(e) # url解析 出来的 数据\n",
    "        #datas = [span.xpath('string(.)') for span in e.xpath('//div[@class=\"content\"]/span[1]')]\n",
    "        urls = self.parse_urls(e) # url 解析出来数据其中的url\n",
    "        #urls = [ 'https://www.qiushibaike.com{}'.format(url) for url in e.xpath('//ul[@class=\"pagination\"]/li/a/@href')]\n",
    "        return datas, urls\n",
    "\n",
    "    # 解析数据的方法\n",
    "    def parse_info(self, e):\n",
    "        spans = e.xpath('//div[@class=\"content\"]/span[1]')\n",
    "        datas = []\n",
    "        for span in spans:\n",
    "            datas.append(span.xpath('string(.)'))\n",
    "        return datas\n",
    "\n",
    "    # 解析数据中url的方法\n",
    "    def parse_urls(self, e):\n",
    "        base_url = 'https://www.qiushibaike.com{}'\n",
    "        urls = []\n",
    "        # url是下一页的href\n",
    "        for url in e.xpath('//ul[@class=\"pagination\"]/li/a/@href'):\n",
    "            print(url)\n",
    "            urls.append(base_url.format(url))\n",
    "        return urls\n",
    "\n",
    "# 数据处理\n",
    "class DataOutPut:\n",
    "    def save(self, datas):\n",
    "        with open('duanzi.txt', 'a', encoding='utf-8') as f:\n",
    "            for data in datas:\n",
    "                f.write(data)\n",
    "\n",
    "# 调度:上边方法怎样合作的\n",
    "class DiaoDu:\n",
    "    # 初始化调度类\n",
    "    def __init__(self):\n",
    "        self.downloader = Downloader()\n",
    "        self.url_manager = URLManager()\n",
    "        self.parser = Parser()\n",
    "        self.data_saver = DataOutPut()\n",
    "\n",
    "    # 调度运行的方法\n",
    "    def run(self, url):\n",
    "        # 添加要解析的url\n",
    "        self.url_manager.add_new_url(url)\n",
    "        # 循环执行: 知道没有要解析的url后跳出\n",
    "        while self.url_manager.has_new_url():\n",
    "            # 得到url\n",
    "            url = self.url_manager.get_new_url()\n",
    "            # 爬取url中的数据\n",
    "            html = self.downloader.download(url)\n",
    "            # 解析爬取url中的数据\n",
    "            data, urls = self.parser.parse(html)\n",
    "            # 保存数据到文本\n",
    "            self.data_saver.save(data)\n",
    "            # 添加解析url中新出现的urls\n",
    "            self.url_manager.add_new_urls(urls)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 构建调度对象\n",
    "    diao_du = DiaoDu()\n",
    "    diao_du.run('https://www.qiushibaike.com/text/page/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
